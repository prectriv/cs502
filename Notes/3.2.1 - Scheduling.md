# Scheduling (processes)

- When to run?
  - After process creation/termination
  - a process blocks
  - interrupt handled

## Short vs Long process

![ex](img/3/shortvslong.png)
- How long does a process run when scheduled
- Short: Processes that are interactive (uses i/o or user input)
  - Relatively short time in 'run' state before they block to wait for IO
- Long: CPU intensive tasks
  - Compute many digits of pi

## Criteria

- Fairness:
  - CPU gives fair share to all processes
- Efficiency:
  - keep cpu busy with user tasks
- Response time

## Measurements

- Execution time (t)
  - Time spent in run state
- Response time (T)
  - Wall-clock time
  - Finish - start time
- Kernel time
  - Spent executing kernel code
- System time
  - kernel time devoted to a process
- User time
  - time CPU spent executing user-level code
- idle time
  - time spent running idle process
- Voluntary switch
  - From run to Block (waiting for I/O)
- Involuntary switch
  - From run to ready when OS either time slices or scheduler has higher priority task that needs to run

## Policies

- first come first serve (FCFS)
  - Non-preemptive policy
  - easy to implement
  - efficient
  - Not necessarily fair 
  - indefinite loops have no way to be broken out of
- Round robbin
  - Ordered queue of ready processes
  - Pick first to run, has a time quantum q 
    - Maximum amount of time a process can run before it must give up the cpu
    - Once reached, an involuntary context switch occurs 
  - If Q is too large, not a fair process
  - If Q is too small, its inefficient
- Shortest process next (spn)
  - Uses historical processes to guess how the current one will run
  - Esmoothaverage = aEsmooth + (1-a)Emeasure
  - a = [0, 1)
    - a = 0 : only use recent value
    - a -> 1 : average changes slowly
  - Fast response time for short processes
  - Bad response time for long processes
    - Could lead to starvation if there are always shorter processes being added to the queue.
- Multiple-level feedback queue (MLFQ)
  - ![EX](img/3/mlfq.png)

## Multiprocessors

- Affinity scheduling
  - Same process may have an affinity for a particular processor
  - Try to repeat scheduling of a process on the same processor
  

## Linux

- "Real-time" processes
  - Processes marked as real time have priority over normal processes
- Normal processes
  - Credit-based policy
  - When a process has more credits, it has more priority
  - credits are awarded in a relation to how much time it uses compared to how much it was allocated
- now has a completely fair scheduler

## Evaluating policies

1) Mathematical analysis
- Queueing theory
2) Simulator
- trace driven
  - take data from real systems and compare with/without policy
3) Experimentation
- Build the scheduler and replace the old one and evaluate distance.
- Would most likely try to justify efforts with first two as to not waste effort

### Page Reference Strings


- Generate a fault rate graph
- X axis is the frame count, and Y axis is the page fault count
  - Usually an exponentially decreasing curve
- Example:
  > ex: 0 1 2 3 0 1 4 0 1 2 3 4 
  - Assuming FIFO
  - 3 frames
  - Pure demand paging
  - Steps:
    - [012] Pages 0 1 2 wil be loaded, each causing a page fault.
      - 'cold start' page faults (not yet filled up frames)
      - The rest are 'warm start' meaning frames are being used and stuff now must be kicked out.
    - [123] Then page 3 is loaded, dropping page 0 causing a page fault
    - [230] Then page 0 is loaded, dropping page 1 and causing a page fault
    - [304] Then page 4 is loaded, dropping page 2 and causing a page fault
    - [---] Then 0 and 1 are accessed again
    - [042] Then 2 is loaded, dropping 0
    - [423] Then 3 is loaded, dropping 1
    - [---] Then 4 is accessed
    - **9 total page faults**
  - Same as before but with 4 frames
    - [0123] each a page fault
    - [----] no page fault loading 0 and then loading 1
    - [1234] page fault generated and dropped 0
    - [2340] page fault reading 0, dropped 1
    - .... So on so forth - will generate **10 total page faults** instead
  - FIFO is a bad algorithm as as you allocate more frames, it does not guarantee less page faults will occur